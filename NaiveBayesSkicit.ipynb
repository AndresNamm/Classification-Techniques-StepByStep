{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Skicit Bayes Classifier\n",
    "\n",
    "We are going to train a naive Bayes classi\fer which predicts whether a document deals with (i) apple the\n",
    "IT company, or (ii) apple the fruit. To this end, you should collect a collection of documents dealing with\n",
    "either topic which you should use to train and test your classi\fer. Twenty documents in total should be\n",
    "su\u000ecient in order to have good accuracy. Use 70% of your documents for training and the rest for testing.\n",
    "The documents should be turned into vectors, which is needed to train the classi\fer. In Python, we can\n",
    "turn the documents into vectors in the Euclidean space as follows:\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "vectors = count_vect.fit_transform(dataFiles)\n",
    "X=vectors.toarray()\n",
    "\n",
    "We then train the Naive Bayes classi\fer in Python as follows:\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, X_train_Cl)\n",
    "where we use the [multinomial Naive Bayes classi\fer](http://scikit-learn.org/stable/modules/\n",
    "generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB) . We then\n",
    "predict the class of instances in the test set by using: clf:predict(X test).\n",
    "\n",
    " You should explain how you partitioned the data into training and test set (e.g. does the training\n",
    "set contains only documents dealing with one topic?) and report the accuracy of the classi\fer on the test\n",
    "set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Handling the folder navigation\n",
    "\n",
    "[How to get the directory](http://stackoverflow.com/questions/918154/relative-paths-in-python)  \n",
    "[List all files in dir](http://stackoverflow.com/questions/3207219/how-to-list-all-files-of-a-directory)  \n",
    "[Humanities text processing tutorial](http://nbviewer.jupyter.org/github/fbkarsdorp/python-course/blob/master/Chapter%202%20-%20First%20steps.ipynb)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "current_dir= os.getcwd()\n",
    "task3= os.path.join(current_dir,\"task3\")\n",
    "\n",
    "task3_fruit = os.path.join(task3,\"fruit\")\n",
    "task3_computer = os.path.join(task3,\"computer\")\n",
    "\n",
    "fruitTxts=[]\n",
    "nerdTxts=[]\n",
    "allTxts=[]\n",
    "\n",
    "for file in os.listdir(task3_fruit):\n",
    "    allTxts.append(os.path.join(task3_fruit,file))\n",
    "fruitFiles=len(allTxts) \n",
    "for file in os.listdir(task3_computer):\n",
    "    allTxts.append(os.path.join(task3_computer,file))\n",
    "nerdFiles=len(allTxts)-fruitFiles\n",
    "\n",
    "#dir = os.path.dirname(__file__)\n",
    "#filename = os.path.join(dir, '/task3/apple 0.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection and Slicing\n",
    "\n",
    "_**References**_\n",
    "\n",
    "  \n",
    "[Document term Matrix](https://de.dariah.eu/tatom/working_with_text.html)  \n",
    "[Concate 2 numpy matrixes](http://stackoverflow.com/questions/20180210/python-how-to-combine-two-matrices-in-numpy)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np  # a conventional alia\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(input='filename', stop_words=\"english\",decode_error='replace' )\n",
    "vectors = vectorizer.fit_transform(allTxts)\n",
    "vocab = vectorizer.get_feature_names()\n",
    "vocab=np.array(vocab)\n",
    "\n",
    "\n",
    "Y1 = np.array([1 for i in range(fruitFiles)])\n",
    "Y2 = np.array([2 for i in range(nerdFiles)])\n",
    "Y = np.concatenate((Y1,Y2))\n",
    "X = vectors.toarray()\n",
    "X1= X[:fruitFiles,:]\n",
    "X2= X[fruitFiles:,:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X_train=np.concatenate((X1[0:6,:], X2[0:6,:]))\n",
    "# Y_train=np.concatenate((Y1[0:6], Y2[0:6]))\n",
    "# X_test=np.concatenate((X1[6:,:], X2[6:,:]))\n",
    "# Y_test=np.concatenate((Y1[6:], Y2[6:]))\n",
    "\n",
    "\n",
    "\n",
    "# print(np.shape(X1))\n",
    "# print(np.shape(X2))\n",
    "# print(np.shape(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "   \n",
    "\n",
    "_**Partitioning**_  \n",
    "\n",
    "[Partiotining into training and test](http://sebastianraschka.com/Articles/2014_scikit_dataprocessing.html)    \n",
    "\n",
    "\n",
    "Explain how you partitioned the data into training and test set (e.g. does the training\n",
    "set contains only documents dealing with one topic?):\n",
    "\n",
    "_As recommended in the tutorial, I used 6 files for training and 3 files for testing in both set. I trained the model with documents from both set together, although there should not be a big difference, because currently there are equal number of documents from both set. Below I have provided the logic behind partitioning of the data.\n",
    ">X_train=np.concatenate((X1[0:6,:], X2[0:6,:]))  \n",
    ">Y_train=np.concatenate((Y1[0:6], Y2[0:6]))  \n",
    ">X_test=np.concatenate((X1[6:,:], X2[6:,:]))  \n",
    ">Y_test=np.concatenate((Y1[6:], Y2[6:]))  \n",
    "\n",
    "_**Building the model**_\n",
    "\n",
    "[Simple MultinomialNB() example](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)  \n",
    "\n",
    "Report the accuracy of the classi\fer on the test\n",
    "set.\n",
    "\n",
    "Accuracy of the test set \n",
    "Formula:\n",
    "\n",
    "_In this case we consider class 1 as yes and class 2 as no. Accuracy = 1 on test set_\n",
    " \n",
    "$$ Accuracy =  \\frac{TP+TN}{TP+FP+TN+FN}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10L, 2863L)\n(10L,)\n(8L, 2863L)\n(8L,)\n[1 1 2 1 2 1 2 1]\n[1 1 2 1 2 1 2 1]\n1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.4, random_state=1)\n",
    "\n",
    "\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(Y_train))\n",
    "\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(Y_test))\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "print(clf.predict(X_test))\n",
    "print(Y_test)\n",
    "\n",
    "print(clf.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold cross validation\n",
    "\n",
    "_References_\n",
    "\n",
    "[Cross Validation](http://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "\n",
    "We are going to evaluate the Naive Bayes classi\fer with a k-fold cross validation using\n",
    "the whole dataset collected. We consider k = 5. In Python, we can use the code below. \n",
    "Average accuracy is 1, which is good. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "data=X\n",
    "label=Y\n",
    "clf = MultinomialNB()\n",
    "scores = cross_val_score(clf, data, label, cv=5)\n",
    "print(scores)\n",
    "#then you can get the mean as the k-fold cross validation value\n",
    "#see more in http://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}